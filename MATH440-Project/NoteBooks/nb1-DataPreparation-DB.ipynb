{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Preparation Notebook\n",
    "\n",
    "## Purpose\n",
    "This notebook is dedicated to preparing all datasets for subsequent analysis. The focus is on assessing, cleaning, structuring, and standardizing data to ensure consistency across analyses.\n",
    "\n",
    "## Datasets Overview\n",
    "This section lists all the datasets involved, such as:\n",
    "- Russian Losses as Documented by Third Party\n",
    "- Ukrainian Losses as Reported by Ukrainian State\n",
    "- [Add others as applicable]\n",
    "\n",
    "## Tools and Libraries\n",
    "This notebook utilizes Python libraries including pandas for data manipulation, SQLAlchemy for database interaction, and NumPy for numerical operations.\n"
   ],
   "id": "c37a6120ef2a98ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "\n",
    "## Import Libraries\n",
    "Here, we import all necessary Python libraries needed for data preparation tasks, including those required for database connectivity.\n",
    "\n",
    "## Define Functions\n",
    "Definition of reusable functions for common data preparation tasks like missing value treatment and normalization is done here. This will ensure consistency and reduce code redundancy throughout the notebook.\n",
    "\n"
   ],
   "id": "31c42210908caedd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T00:16:38.741625Z",
     "start_time": "2024-05-10T00:16:38.278096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine  # Needed for database connection\n",
    "\n",
    "# Ensure psycopg2 or another database adapter is installed\n",
    "# pip install psycopg2-binary if not already installed\n",
    "\n",
    "# TODO: Import any additional libraries needed\n"
   ],
   "id": "deff48eda593a9b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T00:16:41.659369Z",
     "start_time": "2024-05-10T00:16:41.655592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define reusable functions for data preparation\n",
    "def handle_missing_values(data, strategy='mean'):\n",
    "    if strategy == 'mean':\n",
    "        return data.fillna(data.mean())\n",
    "    elif strategy == 'median':\n",
    "        return data.fillna(data.median())\n",
    "    elif strategy == 'zero':\n",
    "        return data.fillna(0)\n",
    "    else:\n",
    "        return data.dropna()\n",
    "\n",
    "def remove_duplicates(data):\n",
    "    return data.drop_duplicates()\n",
    "\n",
    "def convert_data_types(data, column, new_type):\n",
    "    data[column] = data[column].astype(new_type)\n",
    "    return data\n",
    "\n",
    "# TODO: Define any other functions needed for data preparation\n"
   ],
   "id": "d31bf1660d05af34",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Loading\n",
    "\n",
    "## Load Data\n",
    "Each dataset is loaded from its respective source in the database. Detailed instructions and code for loading each specific dataset are provided below.\n",
    "\n"
   ],
   "id": "e5bebec4fd381ea3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T00:17:19.717239Z",
     "start_time": "2024-05-10T00:17:19.702119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Establish a connection to the database\n",
    "engine = create_engine('postgresql://jayton:XF-9HGXtN8Ce9@localhost:5432/russo_ukraine_loss_db')\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "313cb692043eeb20",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load each dataset\n",
    "# TODO: Load Russian Losses as Documented by 3rd Party\n",
    "# TODO: Load Ukrainian Losses as Reported by Ukrainian State\n",
    "# TODO: Load additional datasets as necessary\n"
   ],
   "id": "6e3bee82551bfcab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Assessment\n",
    "\n",
    "## Overview of Data Sources\n",
    "This section provides an initial overview of the data from each source. We will display the column headers from each dataset to identify common data points and differences across sources.\n",
    "\n",
    "## Decision on Comparable Data Points\n",
    "Decisions on which data points are comparable and any necessary combinations of columns (e.g., merging 'Planes' and 'Helicopters' into 'Aircraft') will be documented here.\n"
   ],
   "id": "3d7e83424b5babca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-10T00:35:43.430570Z",
     "start_time": "2024-05-10T00:35:43.419072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load datasets just for displaying headers\n",
    "df_source_documented_headers = pd.read_sql(sql_query_source_documented, engine)\n",
    "\n",
    "sql_query_source_ukraine = \"SELECT * FROM source_ukraine.russian_losses LIMIT 0;\"\n",
    "df_source_ukraine_headers = pd.read_sql(sql_query_source_ukraine, engine)\n",
    "\n",
    "# Display headers from each dataset\n",
    "print(\"Headers from Documented Losses:\")\n",
    "print(df_source_documented_headers.columns.tolist())\n",
    "print(\"\\nHeaders from Russian losses reported by Ukrainian:\")\n",
    "print(df_source_ukraine_headers.columns.tolist())\n"
   ],
   "id": "fd83ad6422d748db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headers from Documented Losses:\n",
      "['date', 'russia_total', 'change_russia', 'ukraine_total', 'change_ukraine', 'ratio_ru_ua', 'russia_destroyed', 'ukraine_destroyed', 'russia_damaged', 'ukraine_damaged', 'ukraine_abandoned', 'russia_abandoned', 'russia_captured', 'ukraine_captured', 'russia_tanks', 'ukraine_tanks', 'russia_tank_capture', 'ukraine_tank_capture', 'russia_afv', 'ukraine_afv', 'russia_afv_capture', 'ukraine_afv_capture', 'russia_ifv', 'ukraine_ifv', 'russia_apc', 'ukraine_apc', 'russia_imv', 'ukraine_imv', 'russia_engineering', 'ukraine_engineering', 'russia_coms', 'ukraine_coms', 'russia_vehicles', 'ukraine_vehicles', 'russia_aircraft', 'ukraine_aircraft', 'russia_infantry', 'ukraine_infantry', 'russia_logistics', 'ukraine_logistics', 'russia_armor', 'ukraine_armor', 'russia_antiair', 'ukraine_antiair', 'russia_artillery', 'ukraine_artillery', 'unhcr_ukraine_border', 'unhcr_ukraine_refugees', 'unhcr_returning_ukraine_refugees']\n",
      "\n",
      "Headers from Russian losses reported by Ukrainian:\n",
      "['date', 'tanks', 'abm', 'artillery_systems', 'mlrs', 'air_defense_equipment', 'planes', 'helicopters', 'uav', 'cruise_missiles', 'ships', 'submarines', 'cars_and_tank_trucks', 'special_equipment', 'personnel']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Discussion on Standardization Needs\n",
    "Based on the headers displayed above, we will discuss and decide which columns should be standardized or combined. This decision process involves considering how each dataset categorizes similar data and the best way to unify them for comparative analysis.\n"
   ],
   "id": "ef394c58847f33a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Standardization\n",
    "\n",
    "## Standardizing Data Names and Formats\n",
    "After reviewing the data, here we implement the changes decided upon, such as combining 'Planes' and 'Helicopters' into a single 'Aircraft' category for consistency.\n",
    "\n",
    "## Save Standardized Data\n",
    "The standardized data is then saved back to the database in new tables prepared for further cleaning and analysis.\n"
   ],
   "id": "a83280e98f6ad0c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Handle Missing Values\n",
    "We detect and handle missing values in each dataset according to the chosen strategy (removal, imputation, etc.).\n",
    "\n",
    "## Remove Duplicates\n",
    "Duplicate entries are identified and removed to ensure data quality.\n",
    "\n",
    "## Data Type Conversion\n",
    "Conversion of data types is performed to ensure correct data formats for analysis, such as converting date strings into datetime objects.\n"
   ],
   "id": "5e5b0468f5ce07c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Handle Missing Values\n",
    "# TODO: Apply missing value handling to each dataset\n",
    "\n",
    "# Remove Duplicates\n",
    "# TODO: Remove duplicates from each dataset\n",
    "\n",
    "# Data Type Conversion\n",
    "# TODO: Convert data types appropriately for each dataset\n"
   ],
   "id": "3b2a1bdb76f7e514"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Transformation\n",
    "\n",
    "## Normalization/Standardization\n",
    "Application of scaling or transformations to normalize data across datasets.\n",
    "\n",
    "## Feature Engineering\n",
    "New features are derived that could be useful for the analysis, such as the difference between reported and documented losses.\n"
   ],
   "id": "3ac3f0f8cca82cde"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Normalization/Standardization\n",
    "# TODO: Normalize or standardize data as required\n",
    "\n",
    "# Feature Engineering\n",
    "# TODO: Derive new features that could be useful for analysis\n"
   ],
   "id": "446516f738462606"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Structuring\n",
    "\n",
    "## Reshape Data\n",
    "Data is organized into a consistent format across all datasets for easier analysis.\n",
    "\n",
    "## Merge/Concatenate\n",
    "Data from different sources is combined if necessary to create a unified dataset for analysis.\n"
   ],
   "id": "cf36291a727456c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Reshape Data\n",
    "# TODO: Organize data into a consistent format across all datasets\n",
    "\n",
    "# Merge/Concatenate\n",
    "# TODO: Combine data from different sources if necessary\n"
   ],
   "id": "371a82efaadb0af0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Quality Checks\n",
    "\n",
    "## Sanity Checks\n",
    "Sanity checks are performed to ensure the integrity of the data after preparation.\n",
    "\n",
    "## Summary Statistics\n",
    "Summary statistics for each dataset are generated to verify proper data preparation and to identify any potential issues early.\n"
   ],
   "id": "425b33c6ddfe7b5f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Sanity Checks\n",
    "# TODO: Perform sanity checks to ensure data integrity\n",
    "\n",
    "# Summary Statistics\n",
    "# TODO: Generate summary statistics to verify data preparation\n"
   ],
   "id": "f5bff3c3931015e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Output\n",
    "\n",
    "## Save Clean Data\n",
    "The cleaned and structured data is saved to new files or databases for easy access in subsequent analysis phases.\n",
    "\n",
    "## Document Output Formats\n",
    "This section describes the format, naming conventions, and storage locations of the cleaned data.\n"
   ],
   "id": "ef7585c73355e609"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save the cleaned and structured data\n",
    "# TODO: Save cleaned data to new files or databases\n"
   ],
   "id": "470bd2c34ea4bf5c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Conclusion\n",
    "\n",
    "## Review\n",
    "A summary of the steps taken and any significant findings or issues encountered during the data preparation phase.\n",
    "\n",
    "## Next Steps\n",
    "Outline of the next steps in the project, pointing towards the Exploratory Data Analysis phase.\n"
   ],
   "id": "52035c44b8468891"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Conclusion of data preparation\n",
    "# TODO: Review and summarize the steps taken in this notebook\n"
   ],
   "id": "7476a4866ee27388"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
